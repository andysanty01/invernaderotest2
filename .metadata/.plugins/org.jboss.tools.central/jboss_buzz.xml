<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">What you need to know about CVE-2021-42392</title><link rel="alternate" href="http://www.mastertheboss.com/jbossas/jboss-datasource/what-you-need-to-know-about-cve-2021-42392/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=what-you-need-to-know-about-cve-2021-42392" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jbossas/jboss-datasource/what-you-need-to-know-about-cve-2021-42392/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=what-you-need-to-know-about-cve-2021-42392</id><updated>2022-01-08T11:23:07Z</updated><content type="html">H2 Console in versions between 1.1.100 and 2.0.204 is vulnerable as it allows loading of custom classes from remote servers through JNDI, like the Log4Shell vulnerability. Let’s see in detail the issue and how this can affect our environment. Starting the H2 Console Firstly, let’s see the source of the issue. H2 ships with a ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">How to run Quarkus applications on Kubernetes</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-run-quarkus-applications-on-kubernetes/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-run-quarkus-applications-on-kubernetes" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/quarkus/how-to-run-quarkus-applications-on-kubernetes/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-run-quarkus-applications-on-kubernetes</id><updated>2022-01-07T09:40:39Z</updated><content type="html">In this article we will learn how to deploy a Quarkus application on top of a Kubernetes cluster. We will start with a minimal REST application and then we will increase its complexity. Hard requirements: A Kubernetes cluster. For the sake of this example we recommend using Minikube (See this article to get started quickly ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Why you should migrate your Java workloads to OpenShift</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/01/07/why-you-should-migrate-your-java-workloads-openshift" /><author><name>Philip Hayes</name></author><id>0080793e-43ef-47a2-8dce-dde082c6a8bd</id><updated>2022-01-07T07:00:00Z</updated><published>2022-01-07T07:00:00Z</published><summary type="html">&lt;p&gt;Despite the incredible pace of adoption of &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; orchestration platforms such as &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;, the vast majority of &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; workloads are still running on virtual machines or bare metal. In many cases, enterprise operation teams are mandated to modernize and move these workloads to the cloud, and OpenShift is the natural destination.&lt;/p&gt; &lt;p&gt;When we talk about &lt;a href="https://developers.redhat.com/products/eap/download"&gt;Red Hat JBoss Enterprise Application Platform (EAP)&lt;/a&gt; migration, developers ask questions such as:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;What does the process involve?&lt;/li&gt; &lt;li&gt;What are the benefits of moving workloads to OpenShift?&lt;/li&gt; &lt;li&gt;How easy is it to move these workloads?&lt;/li&gt; &lt;li&gt;How can you be sure you won't require code changes?&lt;/li&gt; &lt;li&gt;What tools are there to assist with this effort?&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;This article, the first in a two-part series, provides answers to these questions. The second part of the series is a tutorial that walks through the steps to actually migrate a JBoss EAP application to OpenShift.&lt;/p&gt; &lt;h2&gt;Migrating Java applications to OpenShift: What's involved?&lt;/h2&gt; &lt;p&gt;OpenShift is an enterprise Kubernetes platform. Kubernetes is a container orchestration system for automating computer application deployment, scaling, and management. All applications deployed on Kubernetes must be containerized. To containerize an application, an image in compliance with the &lt;a href="https://opencontainers.org"&gt;Open Container Initiative (OCI)&lt;/a&gt; needs to be built containing the required runtime, any additional libraries, and the application code. Red Hat provides a tool to create these images from JBoss EAP applications: The &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.4/html/getting_started_with_jboss_eap_for_openshift_container_platform/build_run_java_app_s2i"&gt;JBoss EAP Source-to-Image (S2I)&lt;/a&gt; builder.&lt;/p&gt; &lt;p&gt;Once the image is built, there are a number of ways (e.g., template, &lt;a href="https://helm.sh"&gt;Helm chart&lt;/a&gt;, &lt;a href="https://www.redhat.com/en/topics/containers/what-is-a-kubernetes-operator"&gt;Kubernetes Operator&lt;/a&gt;) to deploy the application image to OpenShift. My recommendation is to use the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.4/html/getting_started_with_jboss_eap_for_openshift_container_platform/eap-operator-for-automating-application-deployment-on-openshift_default"&gt;JBoss EAP Operator&lt;/a&gt;. This Operator has been designed to simplify some of the operations team's tasks when deploying EAP applications. The Operator supports functionality critical to enterprise-scale applications such as transaction recovery and &lt;a href="https://docs.oracle.com/javaee/5/tutorial/doc/bnblt.html"&gt;Enterprise Java Bean (EJB)&lt;/a&gt; remote calls. Using the Operator, deployment can be as simple as identifying the image and specifying the number of instances to deploy.&lt;/p&gt; &lt;h2&gt;What are the benefits of moving JBoss EAP workloads to OpenShift?&lt;/h2&gt; &lt;p&gt;There are quite a few benefits. Here are some of the main ones:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Reduced operational costs:&lt;/strong&gt; Taking advantage of OpenShift tools—such as the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.3/html/getting_started_with_jboss_eap_for_openshift_container_platform/eap-operator-for-automating-application-deployment-on-openshift_default"&gt;JBoss EAP Operator&lt;/a&gt;, &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/what-is-openshift-service-mesh"&gt;OpenShift Service Mesh&lt;/a&gt;, &lt;a href="https://tekton.dev"&gt;Tekton&lt;/a&gt;, and &lt;a href="https://argoproj.github.io/cd/"&gt;Argo CD&lt;/a&gt;—reduces the load on the operations team.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Improved resource usage:&lt;/strong&gt; The OpenShift JBoss EAP S2I builder tools, since version 7.3 of JBoss EAP, deliver greatly reduced image size and memory footprint through a combination of &lt;a href="https://docs.wildfly.org/galleon/"&gt;Galleon&lt;/a&gt; layer provisioning and use of a JBoss EAP runtime image.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Integrated monitoring and metrics:&lt;/strong&gt; OpenShift integrates application monitoring and metrics through the use of &lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt;. These tools collect metrics from JBoss EAP applications running on OpenShift. In addition, with the &lt;a href="https://developers.redhat.com/blog/2020/06/17/red-hat-jboss-enterprise-application-platform-expansion-pack-1-0-released"&gt;JBoss EAP Expansion Pack (XP)&lt;/a&gt; &lt;a href="https://microprofile.io"&gt;MicroProfile&lt;/a&gt; tools, JBoss EAP applications can report their health status to OpenShift with minimal code.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Improved developer experience:&lt;/strong&gt; OpenShift provides a lot of tools to improve the developer experience, such as the Developer UI (a developer-focused view of the running cluster), continuous integration tools (&lt;a href="https://tekton.dev"&gt;Tekton&lt;/a&gt;), and all the &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt; patterns provided out of the box by OpenShift Service Mesh.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Kubernetes functionality:&lt;/strong&gt; Kubernetes provides a number of services to manage the maintenance and running of application workloads: For example, resource management, application health monitoring, workload scheduling, and horizontal scaling. All combine to make better use of resources and save costs.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Additional benefits from the &lt;a href="https://www.redhat.com/en/products/runtimes"&gt;Red Hat Runtimes&lt;/a&gt; bundle:&lt;/strong&gt; JBoss EAP subscriptions can be converted to Red Hat Runtimes subscriptions at no additional cost. With Red Hat Runtimes, customers get the same level of support for JBoss EAP along with tools essential to developing cloud applications, such as &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat's single sign-on technology&lt;/a&gt;, &lt;a href="https://developers.redhat.com/products/datagrid/overview"&gt;Red Hat Data Grid&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/products/amq/overview"&gt;Red Hat AMQ Broker&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How easy is it to move workloads?&lt;/h2&gt; &lt;p&gt;The enterprise world is all about &lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt;. Migrating a single workload to OpenShift is very straightforward: We'll go through how to do it in the second part of this series. But for large amounts of applications, you'll need to automate this process. Everything we're going to go through in this article can be incorporated into pipelines and automation tools.&lt;/p&gt; &lt;h2&gt;How can you be sure of no code changes?&lt;/h2&gt; &lt;p&gt;At Red Hat, we know JBoss EAP and legacy Java applications well. We also know Kubernetes and what works well in containers. In our experience, JBoss EAP 7 applications rarely require code changes during containerization. A few exceptions exist, such as applications issuing remote method invocations, but these are rare. EJB remoting is more common.&lt;/p&gt; &lt;p&gt;To help you determine whether any code changes are required, Red Hat supplies the &lt;a href="https://developers.redhat.com/products/mta/overview"&gt;migration toolkit for applications&lt;/a&gt;. This tool analyzes Java applications to determine their suitability for migration to a range of target destinations, including containerization. You can run the migration toolkit using the web user interface shown in Figure 1, a command-line interface, a Maven plugin, or an IDE extension. This tool can be used to analyze applications you want to containerize and presents any mandatory or recommended changes in a report.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/mta.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/mta.png?itok=k7dfW2Mp" width="1405" height="941" alt="The graphical interface of Red Hat's migration toolkit for applications offers several options, including Containerization." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1. The graphical interface of the migration toolkit for applications offers several options, including containerization.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;What tools are there to assist with this effort?&lt;/h2&gt; &lt;p&gt;We've already touched on two tools: the JBoss EAP S2I image builder and the migration toolkit for applications.&lt;/p&gt; &lt;p&gt;There is also a range of tools under the &lt;a href="https://www.konveyor.io/"&gt;Konveyor community project&lt;/a&gt;. These tools assist with the migration of workloads to Kubernetes. In addition to tools for rehosting an existing container-based application, rehosting a virtual machine, and migrating an application onto Kubernetes, the Konveyor project also provides tools to manage an enterprise's application portfolio and measure the performance of software delivery by gathering metrics about team and organizational behaviors over time.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The Konveyor project is an upstream project maintained by an open source community, and is not covered by Red Hat support.&lt;/p&gt; &lt;ul&gt;&lt;/ul&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;OpenShift makes application development and deployment easier on many levels. A number of tools, both from the Konveyor project and from Red Hat itself, make it relatively easy to migrate your Java application. Stay tuned for the next article in this series, which will dive into the process step-by-step.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/01/07/why-you-should-migrate-your-java-workloads-openshift" title="Why you should migrate your Java workloads to OpenShift"&gt;Why you should migrate your Java workloads to OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Philip Hayes</dc:creator><dc:date>2022-01-07T07:00:00Z</dc:date></entry><entry><title>Deploying bare-metal clusters from the cloud</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/01/06/deploying-bare-metal-clusters-cloud" /><author><name>Avishay Traeger</name></author><id>e0614bca-043f-4128-8fc0-1f46d038dc96</id><updated>2022-01-06T07:00:00Z</updated><published>2022-01-06T07:00:00Z</published><summary type="html">&lt;p&gt;Our team took a fresh look at installing &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; on bare-metal hardware and developed a software-as-a-service (SaaS) installation service called the &lt;a href="https://console.redhat.com/openshift/assisted-installer/clusters/"&gt;Assisted Installer&lt;/a&gt;, available as a technology preview on the &lt;a href="https://console.redhat.com/"&gt;Red Hat Hybrid Cloud Console&lt;/a&gt;. This article describes the design and architectural choices we made in order to be able to offer the service for both on-premises and cloud deployments, while also continuously improving user experience.&lt;/p&gt; &lt;h2&gt;Installing bare-metal clusters&lt;/h2&gt; &lt;p&gt;Installing clustered software has become simpler with the adoption of virtualization and the cloud, which can provide the requisite infrastructure with a few API calls. Some software is even offered "as a service" on these platforms, allowing users to forgo installation and management.&lt;/p&gt; &lt;p&gt;However, installing bare-metal clusters is more challenging. An infrastructure administrator typically provides connected hardware, IP addresses, and other environmental configurations such as DHCP, DNS, and NTP. The cluster creator then typically configures the clustered software. In case of misconfiguration, the installation fails and the administrators must investigate the cause.&lt;/p&gt; &lt;p&gt;In designing the OpenShift Assisted Installer, our main goal was to provide an excellent user experience. This meant an intuitive and interactive flow that simplified and demystified the configuration inputs, provided early feedback, and, of course, ended with a successful installation.&lt;/p&gt; &lt;h2&gt;From the cloud to bare metal&lt;/h2&gt; &lt;p&gt;Why run the Assisted Installer service on the cloud rather than have users deploy it themselves? There are four reasons:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Users can jump into the installation process without pre-installing any software.&lt;/li&gt; &lt;li&gt;We collect aggregate metrics on usage and failures as a feedback loop for improving the service. Examples of usage information include the popularity of each feature and how many users reach each installation stage. This information helps us see where users experience difficulty with the installation. We also look at where most failures occur, and correlate failures and various parameters such as the OpenShift version or other enabled features.&lt;/li&gt; &lt;li&gt;We can easily help users debug failed installations, as all logs and events are stored by the service.&lt;/li&gt; &lt;li&gt;We deploy new versions of the Assisted Installer often in order to get the latest code into users’ hands, collect feedback quickly from metrics and failed installations, and iterate again.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;These benefits are typical for software deployed as a service. However, bare-metal hardware is not always connected to the Internet and therefore seems like a less natural fit for SaaS. Consequently, we architected the installer service to run either as a scalable SaaS or on-premises in a potentially disconnected environment. Users get all of the benefits from running as a cloud service while also offering stable versions for on-premises deployments.&lt;/p&gt; &lt;h2&gt;Assisted Installer's dual architecture&lt;/h2&gt; &lt;p&gt;Figure 1 highlights the service's deployment-specific areas. The SaaS deployment exposes a user-facing REST API and uses cloud services for storing metadata and files, as shown in red. The service is deployed on-premises as a &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Kubernetes Operator&lt;/a&gt;, exposing a Kubernetes-native &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resource API&lt;/a&gt; and using locally-deployed storage, which is shown in blue. Outside of these few components, the vast majority of the service is identical in both deployment types.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Deploying%20bare-metal%20clusters%20from%20the%20cloud.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Deploying%20bare-metal%20clusters%20from%20the%20cloud.png?itok=vLlC82b9" width="600" height="475" alt="The REST API supports cloud deployments whereas Kubernetes APIs support on-premises deployments." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The REST API supports cloud deployments whereas Kubernetes APIs support on-premises deployments. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The first main difference between the two deployments is the user-facing API. An administrator using the SaaS would use the imperative &lt;a href="https://github.com/openshift/assisted-service/blob/master/swagger.yaml"&gt;REST API&lt;/a&gt;. For an on-premises deployment, they would use the declarative &lt;a href="https://github.com/openshift/assisted-service/tree/master/api"&gt;Kubernetes-native API&lt;/a&gt;. As is standard in Kubernetes, a &lt;a href="https://kubernetes.io/docs/concepts/architecture/controller/"&gt;controller&lt;/a&gt; implements the API logic for a resource in a “reconciliation” function that is called whenever the desired or actual state changes. Each controller compares the desired state of a resource as specified by the administrator with the resource's actual state and executes a series of imperative actions to reach the desired state. The service’s events subsystem, which allows administrators to monitor installations, also triggers the reconciliation whenever the actual state changes.&lt;/p&gt; &lt;p&gt;Before installing, the infrastructure administrator boots any number of hosts with a &lt;em&gt;discovery image&lt;/em&gt; that causes the host to run an agent process. Using the REST API, the agent registers with the installer service and polls for instructions, such as performing various validations and installing itself. The agent-service communication is well-suited for the SaaS: Because hosts are generally not publicly addressable, agents contact the service and not the other way around. We use HTTPS for added security, and the agent can be configured to use an HTTP or HTTPS proxy.&lt;/p&gt; &lt;p&gt;The installer service itself is stateless, storing its state in an SQL database and its files in an object store. This allows the SaaS deployment to scale out to handle the load from many simultaneous users. Kubernetes Operators, on the other hand, store their state in the Kubernetes cluster’s &lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; key-value store. This currently means that we are maintaining the same state in two databases, and the Kubernetes Operator requires a persistent volume, neither of which is ideal. However, we plan to modify the service to treat the SQL database and storage as ephemeral and rely on the key-value store for the source of truth.&lt;/p&gt; &lt;p&gt;One improvement we have in mind for this architecture is to move the Kubernetes Operator into an independent component that interacts with the installer service via a REST API. The resulting operator would be more similar to existing operators interacting with external REST services, such as &lt;a href="https://github.com/crossplane/crossplane"&gt;Crossplane&lt;/a&gt; or &lt;a href="https://github.com/aws-controllers-k8s/community"&gt;ACK&lt;/a&gt;. We would first implement an efficient method for the operator to receive events via a webhook to avoid polling.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;OpenShift's Assisted Installer service illustrates how software that is traditionally on-premises and disconnected can be architected to also run as a service, providing the benefits of fast feedback-update-release cycles. This software reuse, along with a strong user-experience focus, has generated positive user feedback and a high installation success rate for this service.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/01/06/deploying-bare-metal-clusters-cloud" title="Deploying bare-metal clusters from the cloud"&gt;Deploying bare-metal clusters from the cloud&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Avishay Traeger</dc:creator><dc:date>2022-01-06T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak certified as FAPI and Brazil Open Banking provider</title><link rel="alternate" href="https://www.keycloak.org/2022/01/fapi" /><author><name>Marek Posolda</name></author><id>https://www.keycloak.org/2022/01/fapi</id><updated>2022-01-06T00:00:00Z</updated><content type="html">We are glad to announce that Keycloak 15.0.2 was officially certified as ! is a shortcut for Financial-grade API and the FAPI compliance means that Keycloak is now officially able to be used in the highly confidential financial based deployments. Firstly, Keycloak is now certified as FAPI 1 Advanced Final (Generic) provider. For this generic profile, Keycloak is compliant with all the matrix combinations. This means that Keycloak clients are allowed to use , , and client authentication based on or . Keycloak is also certified as Brazil Open Banking provider. For this profile, Keycloak is also compliant with all the matrix combinations. We just did not obtain certification for the DCR, which requires more complicated setup including registration with official Brazil institutions. However some Brazil banks, which are customers of Keycloak based product , were able to obtain DCR certification. So technically, the certification with DCR for any institution using Keycloak or RH-SSO is completely fine. You can see the with the details about the certification. For more details about FAPI support, you can check the with the details to setup your own Keycloak deployment to be FAPI compliant. Keycloak 15.0.2 is also compliant with and we are working to officially obtain the certification for this. Moreover, We plan to re-certify Keycloak 15.0.2 with , which Keycloak certified back in 2016. The FAPI certification was possible just due the awesome work of the . contributed many features related to FAPI, like Client Policies, CIBA, PAR, JARM and others. I hope that year 2022 will be at least as successful as 2021 and there will be even more contributions related to the FAPI as there are more standards being made and more certifications to be obtained. If you are interested in contributing to the Keycloak FAPI support, you are welcome to join FAPI Working Group. It is community working group and it is opened for anyone to join.</content><dc:creator>Marek Posolda</dc:creator></entry><entry><title type="html">Securing LRA endpoints using JWT</title><link rel="alternate" href="https://jbossts.blogspot.com/2022/01/securing-lra-endpoints-using-jwt.html" /><author><name>Mayank Kunwar</name></author><id>https://jbossts.blogspot.com/2022/01/securing-lra-endpoints-using-jwt.html</id><updated>2022-01-05T13:26:00Z</updated><content type="html">INTRODUCTION JWT stands for JSON Web Token, which is a popular way to do user authorization in web application and is also popular in the context of micro-services. So, when we use Long Running Actions (LRA) in any micro-service, the transaction APIs could be authorized using JWT tokens. Open industry standard specification  outlines how JTW is structured and how to use it. JWT works over HTTP protocol. The reason JWT is now a days preferred more is because it makes the authorization mechanism easier for micro-service applications, avoids single point of failure and also helps the application design to be more scalable. Here is how JWT is structured: [&lt;HEADER&gt;.&lt;PAYLOAD&gt;.&lt;SIGNATURE&gt;] The JWT token is divided into three parts, as we can see in the above example which are separated by two periods.     1: HEADER -&gt; base64UrlEncode(header) 2: PAYLOAD -&gt; base64UrlEncode(payload) 3: SIGNATURE -&gt; encryptionAlgorithm(base64UrlEncode(header) + '.' + base64UrlEncode(payload),256-bit-SECRET) You can create your own JWT token by visiting website . JWT is a value token, which will only contain the user information in PAYLOAD, with the name of type of algorithm used in the HEADER and  the token verification signature in the SIGNATURE part. The above figure shows the implication of JWT. The server will create JWT token and will give it to the client, so that client can send it back on the subsequent request. Once the JWT token is created and provided to the client, we can do a REST call to  as below:  curl -H "Authorization:Bearer [&lt;HEADER&gt;.&lt;PAYLOAD&gt;.&lt;SIGNATURE&gt;]" http://127.0.0.1:8080/app/api SECURING LRA ENDPOINTS There are various LRA annotations used, which will internally call the REST APIs that are present in  and  classes. So, below are the recommendations to, how to define roles for each and every APIs in order to create JWT token for client. LRA-endPointsAllowed-roles client client client client client client client client client client system system system admin admin admin admin admin One of the popular tool that could be used to generate JWT tokens would be . Keycloak is an open source identity and access management solution. For more details about Keycloak you can also visit . PROBLEMS WITH JWT AND THEIR SOLUTIONS 1. Anyone can read first two parts of JWT tokens, i.e. HEADER and PAYLOAD, which are only base64 encoded. So, the PAYLOAD part must not contain any confidential information. It should contain enough information so that server could know who the user is. 2. If someone steals your JWT token, it will work for anyone. So in order to avoid the theft, we should be careful about how we are transmitting JWT. It has to be HTTPS connection and by using the process of  which comes with its own security and protection to make sure people don't steal JWT tokens. 3. In compare to session based authentication, if someone steals sessionID, we can log off, which ends the session and it doesn't exist anymore. But in case of JWT there is nothing on the server to end. Since the whole information is inside JWT, we only set expiration for JWT by having expiry PAYLOADs, but we cannot log off. This situation can be handled by creating blacklisted JWTs table at server side and when the request comes to server, that JWT token will be validated if not the blacklisted one then the server will authorize the request if the token had valid signature. 4. If we choose to use Expiry JWT token for LRA, then if the transaction did not complete before the token expiration, then transaction will never complete. So avoid using Expiry JWT tokens with LRA and try to follow above three ways in order to avoid the security breaches.</content><dc:creator>Mayank Kunwar</dc:creator></entry><entry><title>Extracting information from Python source code</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/01/05/extracting-information-python-source-code" /><author><name>Fridolin Pokorny</name></author><id>5a98752f-7df1-4743-ae15-2a435e6a38ab</id><updated>2022-01-05T07:00:00Z</updated><published>2022-01-05T07:00:00Z</published><summary type="html">&lt;p&gt;What library symbols does a &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; source code file use? And what symbols does it provide to its users? A simple tool called &lt;a href="https://github.com/thoth-station/invectio"&gt;invectio&lt;/a&gt; can provide this information based on static source code analysis. &lt;em&gt;Invectio&lt;/em&gt; means “import” in Latin. As the name suggests, this small tool can extract information about imports as well as information about what users can import from Python modules.&lt;/p&gt; &lt;h2&gt;Making Python symbols visible&lt;/h2&gt; &lt;p&gt;The Python standard library contains a module called &lt;a href="https://docs.python.org/3/library/ast.html"&gt;Abstract Syntax Trees&lt;/a&gt; (&lt;code&gt;ast&lt;/code&gt;), with routines to parse Python source code and access it within a program. This capability, along with other parts of the standard library, allows you to examine Python source code and extract information about symbols used or provided. Because this task is widely applicable in many situations, the &lt;a href="http://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt; team has extracted the logic into a simple application that displays the symbols used or exported by source code.&lt;/p&gt; &lt;h2&gt;invectio whatuses&lt;/h2&gt; &lt;p&gt;The first command available in &lt;code&gt;invectio&lt;/code&gt; extracts information about symbols used in the source files. Let's consider a simple &lt;a href="https://pypi.org/project/flask"&gt;Flask&lt;/a&gt; application:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;import flask app = flask.Flask(__name__) @app.route("/") def hello_world(): return flask.jsonify({})&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Running &lt;code&gt;invectio whatuses&lt;/code&gt; extracts information about symbols used from other modules, the use of built-in symbols, and Python standard library symbols. The output is in JSON format:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;$ invectio whatuses test.py { "report": { "test.py": { "__builtins__": [ "__builtins__.__name__" ], "flask": [ "flask.Flask", "flask.jsonify" ] } }, "version": "0.2.0" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The tool can also take a directory as an argument and display the symbols from all the Python source files in that directory.&lt;/p&gt; &lt;h2&gt;invectio whatprovides&lt;/h2&gt; &lt;p&gt;Another &lt;code&gt;invectio&lt;/code&gt; subcommand extracts information about functions, classes, and constants available in the source code. Consider the following Python source code:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;CONST = 42 def is_palindrome(s: str) -&gt; bool: return s == s[::-1] # TODO: optimize&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Running &lt;code&gt;invectio whatprovides&lt;/code&gt; gives insights about symbols provided by the module:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;$ invectio whatprovides module.py { "report": { "module.py": [ "module.CONST", "module.is_palindrome" ] }, "version": "0.2.0" } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Like the &lt;code&gt;whatuses&lt;/code&gt; subcommand, the &lt;code&gt;whatprovides&lt;/code&gt; subcommand can work on directories to inspect all the Python source code present in a directory.&lt;/p&gt; &lt;h2&gt;How to install and use invectio&lt;/h2&gt; &lt;p&gt;Invectio is available as a &lt;a href="https://pypi.org/project/invectio/"&gt;Python package on PyPI&lt;/a&gt;. To install it, just enter the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ pip install invectio&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The project source files are hosted on GitHub in Project Thoth's &lt;a href="https://github.com/thoth-station/invectio"&gt;invectio repository&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;About Project Thoth&lt;/h2&gt; &lt;p&gt;This tool was developed by &lt;a href="http://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt;, part of the Artificial Intelligence Center of Excellence group (AICoE). As part of Project Thoth, we are accumulating knowledge to help Python developers create healthy applications. The introduced tool, invectio, is integrated into Thoth's client applications that aggregate information for &lt;a href="https://developers.redhat.com/articles/2021/11/17/customize-python-dependency-resolution-machine-learning"&gt;Thoth's resolver to give better guidance to developers&lt;/a&gt; on dependencies they use. If you would like to follow updates in Project Thoth, feel free to &lt;a href="https://www.youtube.com/channel/UClUIDuq_hQ6vlzmqM59B2Lw"&gt;subscribe to our YouTube channel&lt;/a&gt; or follow us on the &lt;a href="https://twitter.com/thothstation"&gt;@ThothStation Twitter handle&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/01/05/extracting-information-python-source-code" title="Extracting information from Python source code"&gt;Extracting information from Python source code&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Fridolin Pokorny</dc:creator><dc:date>2022-01-05T07:00:00Z</dc:date></entry><entry><title type="html">Orchestrate web services using RHPAM and AMQ</title><link rel="alternate" href="https://blog.kie.org/2022/01/orchestrate-web-services-using-rhpam-and-amq.html" /><author><name>Diego Torres Fuerte</name></author><id>https://blog.kie.org/2022/01/orchestrate-web-services-using-rhpam-and-amq.html</id><updated>2022-01-04T23:05:42Z</updated><content type="html">We, at the Intelligent Application Practice, recently received the request from one of our TELCO customers to provide a proof of concept about orchestrate web services using RHPAM and AMQ. Additionally, I recently came across the following post in the internet, explaining that REST is not the only way to integrate web service communication: . The previous post may give you an idea on what we are trying to accomplish here: we often think about invoking web services from our BPMN processes: Invoking an external web service from BPMN Process We have multiple ways to resolve this implementation. For example, the , that help us send a REST/HTTP request, so that we can integrate our processes with remote web services. We also have the that produces a message in a given queue name, although it seems also to default to the KIE-SERVER SIGNAL QUEUE used to complete work items. In both cases, the situation that arises is that both work item handlers act to interact with the external web service, and later complete the work item that generated the action. In our proof of concept here, we need to avoid that work item completion, so that an external entity provides in a later time, asynchronously, the completion event, along with information about the result of the remote web service execution, as in the following example: BPMN Process waiting for the remote service response Note that the process here is waiting for the external web service to integrate its response back to the BPMN process, containing the response to the inventory system on weather there was enough materials or not, so that our process can take the next gateway action appropriately, like described in the following picture: Integrate response from remote web service into BPMN Process This is accomplished with the following custom work item handler implementation: import javax.ejb.Stateless; import javax.ejb.TransactionAttribute; import javax.ejb.TransactionAttributeType; import javax.jms.Connection; import javax.jms.ConnectionFactory; import javax.jms.JMSException; import javax.jms.Message; import javax.jms.MessageProducer; import javax.jms.Queue; import javax.jms.Session; import javax.naming.InitialContext; import javax.naming.NamingException; import org.jbpm.process.workitem.core.AbstractLogOrThrowWorkItemHandler; import org.kie.api.runtime.process.WorkItem; import org.kie.api.runtime.process.WorkItemManager; import org.kie.internal.runtime.Cacheable; @Stateless public class SimpleExternalCaller extends AbstractLogOrThrowWorkItemHandler implements Cacheable { private static final int DEFAULT_PRIORITY = 5; private static final String TARGET_QUEUE = "java:/QUEUE/INBOUND"; // [1] private String connectionFactoryName = System.getProperty("org.kie.executor.jms.cf", "java:/JmsXA"); // [2] private ConnectionFactory connectionFactory; private boolean transacted = true; public SimpleExternalCaller() { super(); try { InitialContext context = new InitialContext(); if (this.connectionFactory == null) { this.connectionFactory = (ConnectionFactory) context.lookup(connectionFactoryName); } } catch (NamingException e) { // Catch action for configuration error } } @TransactionAttribute(value = TransactionAttributeType.MANDATORY) @Override public void executeWorkItem(WorkItem workItem, WorkItemManager manager) { if (connectionFactory == null) { handleException(new RuntimeException( "Failed when assigning value for AMQ connection, check the messaging configuratio")); } else { Connection queueConnection = null; Session queueSession = null; try { queueConnection = connectionFactory.createConnection(); queueSession = queueConnection.createSession(transacted, Session.AUTO_ACKNOWLEDGE); sendMessage(queueSession, TARGET_QUEUE, workItem); // [3] } catch (Exception e) { handleException(e); } finally { if (queueSession != null) { try { queueSession.close(); } catch (JMSException qce) { // catch exception while closing connection } } if (queueConnection != null) { try { queueConnection.close(); } catch (JMSException cce) { // catch exception while closing connection } } } } } private void sendMessage(Session queueSession, String queueName, WorkItem workItem) throws NamingException, JMSException { InitialContext context = new InitialContext(); Queue queue = (Queue) context.lookup(queueName); Connection queueConnection = null; MessageProducer producer = null; try { queueConnection = connectionFactory.createConnection(); queueSession = queueConnection.createSession(transacted, Session.AUTO_ACKNOWLEDGE); Message message = queueSession .createTextMessage("{'partNumber': 123, 'quantity': 300, 'assemblyLine':'abc-def'}"); String businessAutomationToken = workItem.getParameter("appName") + ":" + workItem.getProcessInstanceId() + ":" + workItem.getId(); message.setStringProperty("baToken", businessAutomationToken); // [4] producer = queueSession.createProducer(queue); queueConnection.start(); producer.setPriority(DEFAULT_PRIORITY); producer.send(message); } catch (Exception e) { handleException(e); } finally { if (producer != null) { try { producer.close(); } catch (JMSException pce) { // catch exception while closing connection to producer throw pce; } } } } @Override public void abortWorkItem(WorkItem workItem, WorkItemManager manager) { // No action to be taken during work item abort } @Override public void close() { // Nothing to release when container is removed } } IMPLEMENTATION NOTES 1. The destination queue is hard-coded to be QUEUE/INBOUND, this QUEUE needs to be part of the naming assets in the EAP web service, see the section that explains how to configure this outbound destination. 2. The connection factory name, is also part of the naming resources in the server, here we are using the same system property name that the uses to define its connection factory for the AMQ broker, if the property is not given to the system properties of the kie-server, we default that value to java:/JmsXA. See the section that explains how the remote connection is established. 3. We send the message to the defined queue, note that after this instruction, we are not “completing” the work item like other implementations, in our case, the work item creates a wait state until an external entity completes the work item using remote resources, such as the (Search for the endpoint that “Completes a specified work item”), or as we will see in the section, we use the to complete the work item through JMS. 4. The remote web service will need to know information about the work item that is generating the message, so that when in produces a response, it will be able to send the reference information back to RHPAM about the work item that RHPAM is requested to complete with certain data. We will call this reference number the “Business Automation Token”. The Business Automation Token, or B-A-Token for short, includes information about the deployment id, the process instance id, and the work item id that generated the request. See the section for information on how the remote web service generates the proper response. CONNECT RHPAM TO EXTERNAL AMQ BROKER A vital part for orchestrate web services using RHPAM and AMQ, is to make RHPAM to identify the location of the remote AMQ broker, so that it can produce messages to it, and consume messages from it. The RHPAM configuration to identify the AMQ Broker depends on the JNDI configuration for messaging subsystem in the . LOCAL SETUP For a local setup of this PoC, let’s start by Q broker: 1. Unzip the AMQ product locally. 2. Install a broker by running the command: ${ARTEMIS_HOME}/bin/activemq create broker 3. Start the broker by running the command: ${broker_home}/bin/activemq run You can also find useful information . Now, let’s install a RHPAM local instance: 1. Download and unzip EAP server to your local environment. 2. Download and unzip business-central deployable. 3. Merge the contents of business-central deployable into the EAP server directory. 4. Download and unzip kie-server deployable. 5. Place the kie-server.war in the $EAP_HOME/standalone/deployments directory, and create a file named kie-server.war.dodeploy. 6. Uncomment the sections for the controllerUser configuration at standalone-full.xml, application-roles.properties, and application-users.properties. Of course, there are , but I prefer this manual summary of actions, I feel that I have more control about what is being changed to locally install what I need. Now, here comes the Local Setup, if as a pre-requisite you already had RHPAM and AMQ broker installed, you can directly follow these steps to allow RHPAM to connect to AMQ broker: 1. In the standalone-full.xml, create an outbound-socket-binding, with a remote destination to the host and port of your amq broker: &lt;socket-binding-group name="standard-sockets" default-interface="public" port-offset="${jboss.socket.binding.port-offset:0}"&gt; &lt;socket-binding name="ajp" port="${jboss.ajp.port:8009}"/&gt; &lt;socket-binding name="http" port="${jboss.http.port:8080}"/&gt; &lt;socket-binding name="https" port="${jboss.https.port:8443}"/&gt; &lt;socket-binding name="iiop" interface="unsecure" port="3528"/&gt; &lt;socket-binding name="iiop-ssl" interface="unsecure" port="3529"/&gt; &lt;socket-binding name="management-http" interface="management" port="${jboss.management.http.port:9990}"/&gt; &lt;socket-binding name="management-https" interface="management" port="${jboss.management.https.port:9993}"/&gt; &lt;socket-binding name="txn-recovery-environment" port="4712"/&gt; &lt;socket-binding name="txn-status-manager" port="4713"/&gt; &lt;outbound-socket-binding name="mail-smtp"&gt; &lt;remote-destination host="localhost" port="25"/&gt; &lt;/outbound-socket-binding&gt; &lt;outbound-socket-binding name="messaging-remote-throughput"&gt; &lt;remote-destination host="localhost" port="61616"/&gt; &lt;/outbound-socket-binding&gt; &lt;/socket-binding-group&gt; Pay special attention to the "name", in this case to be "messaging-remote-throughput", you can assign the name you want, but you will use it in the next steps. 2. In the messaging-activemq subsystem, add a remote-connector that uses your previously created socket-binding 3. In the same messaging-activemq subsystem, add a pooled-connection-factory, that defines java:JmsXA as part of its entries, your previously created remote-connector as the connector, and the credentials to authenticate to the remote AMQ. &lt;subsystem xmlns="urn:jboss:domain:messaging-activemq:8.0"&gt; &lt;server name="default"&gt; &lt;statistics enabled="${wildfly.messaging-activemq.statistics-enabled:${wildfly.statistics-enabled:false}}"/&gt; &lt;security-setting name="#"&gt; &lt;role name="guest" send="true" consume="true" create-non-durable-queue="true" delete-non-durable-queue="true"/&gt; &lt;/security-setting&gt; &lt;address-setting name="#" dead-letter-address="jms.queue.DLQ" expiry-address="jms.queue.ExpiryQueue" max-size-bytes="10485760" page-size-bytes="2097152" message-counter-history-day-limit="10"/&gt; &lt;http-connector name="http-connector" socket-binding="http" endpoint="http-acceptor"/&gt; &lt;http-connector name="http-connector-throughput" socket-binding="http" endpoint="http-acceptor-throughput"&gt; &lt;param name="batch-delay" value="50"/&gt; &lt;/http-connector&gt; &lt;remote-connector name="netty-remote-throughput" socket-binding="messaging-remote-throughput"/&gt; &lt;in-vm-connector name="in-vm" server-id="0"&gt; &lt;param name="buffer-pooling" value="false"/&gt; &lt;/in-vm-connector&gt; &lt;http-acceptor name="http-acceptor" http-listener="default"/&gt; &lt;http-acceptor name="http-acceptor-throughput" http-listener="default"&gt; &lt;param name="batch-delay" value="50"/&gt; &lt;param name="direct-deliver" value="false"/&gt; &lt;/http-acceptor&gt; &lt;in-vm-acceptor name="in-vm" server-id="0"&gt; &lt;param name="buffer-pooling" value="false"/&gt; &lt;/in-vm-acceptor&gt; &lt;jms-queue name="ExpiryQueue" entries="java:/jms/queue/ExpiryQueue"/&gt; &lt;jms-queue name="DLQ" entries="java:/jms/queue/DLQ"/&gt; &lt;connection-factory name="InVmConnectionFactory" entries="java:/ConnectionFactory" connectors="in-vm"/&gt; &lt;connection-factory name="RemoteConnectionFactory" entries="java:jboss/exported/jms/RemoteConnectionFactory" connectors="http-connector"/&gt; &lt;pooled-connection-factory name="activemq-ra" entries="java:/JmsXALocal java:jboss/DefaultJMSConnectionFactory" connectors="in-vm" transaction="xa"/&gt; &lt;pooled-connection-factory name="activemq-ra-remote" entries="java:/JmsXA java:/RemoteJmsXA java:jboss/RemoteJmsXA" connectors="netty-remote-throughput" transaction="xa" user="admin" password="admin"/&gt; &lt;/server&gt; &lt;/subsystem&gt; Note that probably the java:/JmsXA was previously part of the activemq-ra connection factory, and we are moving that entry here to the activemq-ra-remote connection factory. 4. Set the Message Driven Bean resource adapter at the EJB3 subsystem to resolve the remote nature of our QUEUES: &lt;subsystem xmlns="urn:jboss:domain:ejb3:6.0"&gt; &lt;session-bean&gt; &lt;stateless&gt; &lt;bean-instance-pool-ref pool-name="slsb-strict-max-pool"/&gt; &lt;/stateless&gt; &lt;stateful default-access-timeout="5000" cache-ref="simple" passivation-disabled-cache-ref="simple"/&gt; &lt;singleton default-access-timeout="5000"/&gt; &lt;/session-bean&gt; &lt;mdb&gt; &lt;resource-adapter-ref resource-adapter-name="${ejb.resource-adapter-name:activemq-ra-remote.rar}"/&gt; &lt;bean-instance-pool-ref pool-name="mdb-strict-max-pool"/&gt; &lt;/mdb&gt; &lt;!-- MORE PROPERTIES REMOVED FOR BREVITY --&gt; &lt;/subsystem&gt; It appears to be a file name (activemq-ra-remote.rar), but it really is a reference to our previously created pooled-connection-factory. REGISTER DESTINATION QUEUE The QUEUEs are resolved by JNDI mechanism, so that when we call the connection factory from our InitialContext in our code, it will try to find the proper naming. Thus, we need to define how our local EAP can resolve those queue names in the remote AMQ. For this purpose, add a bindings section to the naming subsystem, as in the following snippet: &lt;subsystem xmlns="urn:jboss:domain:naming:2.0"&gt; &lt;bindings&gt; &lt;external-context name="java:global/remoteContext" module="org.apache.activemq.artemis" class="javax.naming.InitialContext"&gt; &lt;environment&gt; &lt;property name="java.naming.factory.initial" value="org.apache.activemq.artemis.jndi.ActiveMQInitialContextFactory"/&gt; &lt;property name="java.naming.provider.url" value="tcp://localhost:61616"/&gt; &lt;property name="queue.QUEUE/EXECUTOR" value="QUEUE/EXECUTOR"/&gt; &lt;property name="queue.QUEUE/RESPONSE" value="QUEUE/RESPONSE"/&gt; &lt;property name="queue.QUEUE/REQUEST" value="QUEUE/REQUEST"/&gt; &lt;property name="queue.QUEUE/SIGNAL" value="QUEUE/SIGNAL"/&gt; &lt;property name="queue.QUEUE/AUDIT" value="QUEUE/AUDIT"/&gt; &lt;property name="queue.QUEUE/INBOUND" value="QUEUE/INBOUND"/&gt; &lt;/environment&gt; &lt;/external-context&gt; &lt;lookup name="java:/QUEUE/EXECUTOR" lookup="java:global/remoteContext/QUEUE/EXECUTOR"/&gt; &lt;lookup name="java:/QUEUE/RESPONSE" lookup="java:global/remoteContext/QUEUE/RESPONSE"/&gt; &lt;lookup name="java:/QUEUE/REQUEST" lookup="java:global/remoteContext/QUEUE/REQUEST"/&gt; &lt;lookup name="java:/QUEUE/SIGNAL" lookup="java:global/remoteContext/QUEUE/SIGNAL"/&gt; &lt;lookup name="java:/QUEUE/AUDIT" lookup="java:global/remoteContext/QUEUE/AUDIT"/&gt; &lt;lookup name="java:/QUEUE/INBOUND" lookup="java:global/remoteContext/QUEUE/INBOUND"/&gt; &lt;/bindings&gt; &lt;remote-naming/&gt; &lt;/subsystem&gt; Note here that we are binding the 5 QUEUES that RHPAM would probably use for its functions, as well as the QUEUE that we will use for the remote system communication (QUEUE/INBOUND). Find the end result standalone-full.xml . ENABLING SIGNAL JMS Message listeners in EAP are performed with (MDB). It is important for you to know that nothing prevents you from developing your own MDB, and deploy that MDB to the execution context of the EAP server to start reading messages from those queues, or more if you want. Then, using the service discovery from the EAP server, discover the RHPAM runtime engine and do whatever you want with your kjar, assets, and instances. By knowing that information, the sky is the limit and you will have all the power to customize the KIE-SERVER listeners to your liking. But let’s get this simpler, RHPAM already has pre-defined MDBs that are listening to messages, in our case, we will leverage the existence of the to help us complete our work item when a message is received at the QUEUE/SIGNAL queue. To enable the MDB, you need to modify the kie-server.war’s ejb-jar.xml file (find this file at $EAP_HOME/standalone/deployments/kie-server.war/WEB-INF/ejb-jar.xml), in the ejb-jar.xml you need to make sure that the JMSSignalReceiver bean is not commented out, and you can also include the QUEUE name that it is listening to: &lt;message-driven&gt; &lt;ejb-name&gt;JMSSignalReceiver&lt;/ejb-name&gt; &lt;ejb-class&gt;org.jbpm.process.workitem.jms.JMSSignalReceiver&lt;/ejb-class&gt; &lt;transaction-type&gt;Bean&lt;/transaction-type&gt; &lt;activation-config&gt; &lt;activation-config-property&gt; &lt;activation-config-property-name&gt;destinationType&lt;/activation-config-property-name&gt; &lt;activation-config-property-value&gt;javax.jms.Queue&lt;/activation-config-property-value&gt; &lt;/activation-config-property&gt; &lt;activation-config-property&gt; &lt;activation-config-property-name&gt;destination&lt;/activation-config-property-name&gt; &lt;activation-config-property-value&gt;java:/QUEUE/SIGNAL&lt;/activation-config-property-value&gt; &lt;/activation-config-property&gt; &lt;/activation-config&gt; &lt;/message-driven&gt; For the sake of completion, and preparing for multi-tenant situations, in the we are also enabling the MDBs for the EXECUTOR, and KIE-SERVER, these listeners would enable additional interactions of kie-servers with the AMQ broker. REPLYING TO RHPAM If you reach this point, start your AMQ Broker, deploy a kjar that uses the work item handler to your running kie-server, and start a process instance, you will reach the point where the process produces a message in the INBOUND queue. At last we need an application now, known as the remote web service, that reads the message from the INBOUND queue, performs some logic, and replies to RHPAM with the result of its operation. A simple class that performs these sort of operations in spring-boot looks like this: import static org.kie.server.api.jms.JMSConstants.CONTAINER_ID_PROPERTY_NAME; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.ObjectOutputStream; import java.util.HashMap; import java.util.Map; import javax.jms.BytesMessage; import javax.jms.JMSException; import javax.jms.Message; import javax.jms.Session; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.jms.annotation.JmsListener; import org.springframework.jms.core.JmsTemplate; import org.springframework.jms.core.MessageCreator; import org.springframework.messaging.MessageHeaders; import org.springframework.stereotype.Component; @Component public class QueueAReceiver { private static final Logger logger = LoggerFactory.getLogger(QueueAReceiver.class); private static final String REQUEST_QUEUE = "QUEUE/SIGNAL"; @Autowired private JmsTemplate jmsTemplate; @JmsListener(destination = "QUEUE/INBOUND", containerFactory = "remoteConnectionFactory") public void receiveMessage(String partsProcurementJson, MessageHeaders messageHeaders) { String baToken = (String) messageHeaders.getOrDefault("baToken", "UNKNOWN"); logger.info("Received message for baToken: {}", baToken); logger.info("Received message &lt;{}&gt;", partsProcurementJson); logger.debug("Producing a message for RHPAM to continue operation with baToken {}", baToken); String[] tokenParts = baToken.split(":"); String deploymentId = tokenParts[0]; Long processInstanceId = Long.parseLong(tokenParts[1]); Long workItemId = Long.parseLong(tokenParts[2]); Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put("partsAvailable", Boolean.TRUE); jmsTemplate.send(REQUEST_QUEUE, new MessageCreator() { @Override public Message createMessage(Session session) throws JMSException { BytesMessage message = session.createBytesMessage(); // TODO: this correlation key works better if it is unique, it helps correlate // responses in the RESPONSE QUEUE, with requests in the SIGNAL QUEUE. message.setJMSCorrelationID(baToken); message.setStringProperty(CONTAINER_ID_PROPERTY_NAME, deploymentId); message.setObjectProperty("KIE_DeploymentId", deploymentId); message.setObjectProperty("KIE_SignalWorkItemId", workItemId); message.setObjectProperty("KIE_SignalProcessInstanceId", processInstanceId); try { message.writeBytes(convertToBytes(params)); } catch (IOException e) { logger.error("Unable to serialize parameters to bytes", e); } return message; } }); } private byte[] convertToBytes(Object object) throws IOException { try (ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream out = new ObjectOutputStream(bos)) { out.writeObject(object); return bos.toByteArray(); } } } Find more information about consuming and producing messages in AMQ . Note in our code that we are using some coupling requirements from the so that it can understand our reply: 1. The CONTAINER_ID_PROPERTY_NAME is a constant defined in the kie-server api library, but the other strings required by the receiver are not, so that they are required to find the work item to complete. 2. The message is a byte message with the serialized representation of the Map&lt;String, Object&gt; with the parameters to send to the signal. If you happen to send a custom object in one of those entries, it better implements the Serializable interface, or you will lose its value. DEMO Here I leave you as last part of my post a demo of the previously configured instance, I am planning to later work with one of my team mates to publish an Openshift implementation, and to implement some more elegant pattern of integration, such as the SAGA pattern using these tools. Thanks for reading this far, now go and automate the world. The post appeared first on .</content><dc:creator>Diego Torres Fuerte</dc:creator></entry><entry><title type="html">Getting started with Netty</title><link rel="alternate" href="http://www.mastertheboss.com/jboss-frameworks/netty/jboss-netty-tutorial/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=jboss-netty-tutorial" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jboss-frameworks/netty/jboss-netty-tutorial/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=jboss-netty-tutorial</id><updated>2022-01-01T03:35:00Z</updated><content type="html">Netty is a client/server framework that provides a simplified layer over NIO networking. This makes it a good candidate to create low-level nonblocking network applications. Overview of Netty Before we begin with a practical example, let’s see the main highlights of Netty framework: Ease of use: Netty is simpler to use than plain Java NIO ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">2021 year in review - The new normal?</title><link rel="alternate" href="http://www.schabell.org/2021/12/2021-year-in-review.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2021/12/2021-year-in-review.html</id><updated>2021-12-31T06:00:00Z</updated><content type="html">The year 2021 is coming to a close, ending pretty much the same way here in the Netherlands as it started in 2020... a lockdown. Empty streets, closed shops, closed restaurants, no parties, no gatherings, and all just when we thought it might be getting back to normal. Not yet. Meanwhile work has gone one and life has continued for me with little change other than the occasional possibility to get out and about to visit you. Just like in 2020, we've shared more time together this year online in virtual events, coffee breaks, and other strange virtual events. On the up side there were the possibilities to travel again in 2021 and I got to spend time with my family back in the US for the first time in over three years! This year I spent all my time generating architecture content, upgrading demos, updating workshops, and spreading as much good cheer as I could from behind my webcam. I was able to visit a few customers in the Netherlands and even get out and about for an overseas event in Ireland, but I'll get to that in a bit. It was my +12th year at Red Hat and the worldwide pandemic continued to influence our daily lives as it surged and subsided throughout the year. While it's a constant in all the planning and activities, let's review some of the activities from 2021 that were not affected by the pandemic. PUBLISHING Again this year I've been publishing a lot online, maybe even more so now that the events are all virtual  and I needed to float new ideas for your review. This year I've published  on this site, many were , and multiple articles featured elsewhere on external sites.  I also did a few special writing projects, such as the . My hobby of writing as  continued, but slowed considerably due to the shortened season and my time being used up elsewhere. It's been amazing to share these insights and experiences that can make others better at what they do. It's the most rewarding part of working in open source, the sharing, mentoring, and collaboration that makes all around you grow. Speaking engagements were numerous, but mostly virtual until the in person event in Ireland (see travel below). One of the more fun ones was a workshop I delivered during my vacation from a hotel on an island in Greece, always a challenge! There were too many speaking engagements to list here so just sending you over to my for the listing and content made available from my sessions there. Here are some of the feedback that was shared throughout the year: “Was in a class last week, about becoming a manager. And they asked a question about who inspire you the most as a leader, guess who came to my mind first &#x1f61b;. You &#x1f600;. I think a true leader leads by example. And just want you should know how much you inspired me.” “Pleasure having you around. A good man with a good heart.” “Thanks Eric, you are an amazing person and someone I always enjoyed working with." “Many thanks for all your help Eric and for all the top material you create, it is absolutely helpful and a big asset to spread the word of what we at Red Hat can do. Really enjoy working with you, man!” “Do we have a UI for Eric's brain? Like, I can just type in a TLA and get a printout?” “DZone Community Member of the Day: Eric D. Schabell. Long-time DZone contributor he’s  posted over 300 articles on DZone that have generated over 2.1 million page views.” “Well done Eric! Amazing to see how much you have contributed back to the community by sharing your knowledge”  “Such a fun session! Took a ton of notes to better understand the environment and opportunities available for hybrid cloud and digital transformation. Should take the band on the road guys!”“Well done Eric! Amazing to see how much you have contributed back to the community by sharing your knowledge”  “Thanks Eric, this is really useful to learn the main features of PAM.!”  “You’re leaders in this space (Portfolio Architecture), this is just awesome content!” CODING AND OTHER CONTENT This year saw the  complete its sixth year since the first commit on April 1, 2016 and is hosted on Gitlab. This year it continued to expand beyond the projects illustrating containers, cloud operations, deployments, AppDev in the Cloud to include more portfolio architecture workshops and example repositories. Be sure to jump on over there and watch the updates as container based projects are migrating to OpenShift Container Platform 4.x and beyond. Almost all of my workshops and demo projects have been updated and are based on installing using OpenShift through the CodeReady Containers offering or just native containers with : * : * * * * * : * * * These workshops are all constantly undergoing revisions and updates to add new product innovations so be sure to check them out thorough next year. The biggest work I've delivered on this year can be found in the  repository where I've added 12 new architecture projects ranging from cloud adoption, remote server management, retail, and healthcare projects. This is just the public facing content, there is more but that's targeting enablement of the internal field teams at Red Hat. TRAVEL This year the travel was a bit better than 2020, but not by much. Several lockdowns hampered travel for most of us, but here's the overview. Just for reference, back in 2019 a normal travel year was over 138,000 km, 22 cities, and 9 countries. In 2021 it was just five trips covering 22,914km, 8 cities, and 4 countries.  Four of those trips were personal vacations, so only one trip was made for work:  * Dublin, Ireland (work) One can only hope we are meeting even more face to face soon in 2022 and I'm seeding conferences with sessions throughout the coming year to be ready when it happens. TIME FOR OTHER PROJECTS The positive side of this lack of travel is that I've worked on a lot of physical projects around my home again in 2021. I'm a type of person that likes to fix stuff that breaks down himself, so I have turned my attentions to maintenance and improvements for my home along with some professional builders for the bigger projects: * painted three more interior doors and all their door frames * remodelled two bathrooms * remodelled fireplace * replaced four external windows and repainted frames * started playing with mobile development around react-native As long as the travel is not taking up all my time I'll plan to continue with the maintenance work in 2022. THANKS TO YOU ALL Here is hoping you enjoyed what I was able to bring to you in 2021. I'm sharing, entertaining, and hopefully slipping in a bit of educational content for your daily lives. I want to thank you personally for attending any of the webinars, virtual conference sessions, online workshops, and for taking the time to read my published articles. As 2022 kicks off, there's hope for travel and in person events, but using the mediums we have at our disposal we'll continue to explore the amazing things you can achieve with open technologies. Finally, stay safe, take care of yours, and hope to see you soon face to face!</content><dc:creator>Eric D. Schabell</dc:creator></entry></feed>
